{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7beec219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as pyplot\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18400be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_captcha_label(file_path):\n",
    "    \"\"\"\n",
    "    Precondition: 80x60 dimension CAPTCHA images were generated using the\n",
    "                  'generator.py' script found in this project folder\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): the path to the CAPTCHA image\n",
    "    \n",
    "    Returns:\n",
    "        the 'label' for each CAPTCHA denoted by the \n",
    "        string in the file name before the '_'\n",
    "        character\n",
    "\n",
    "        Example: '9876_image.png' -> '9876' \n",
    "    \"\"\"\n",
    "    try:\n",
    "        path, file_name = os.path.split(file_path)\n",
    "        file_name, extension = os.path.splitext(file_name)\n",
    "        label, _ = file_name.split(\"_\")\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print('error while parsing %s. %s' % (file_path, e))\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24da397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_captcha_dataframe(captcha_images_directory):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        captcha_images_directory (str): the full file path to the folder where the captcha images\n",
    "                                        were generated\n",
    "    \n",
    "    Returns:\n",
    "        a pandas.DataFrame object storing each captcha file name along with its label\n",
    "    \"\"\"\n",
    "    files = glob.glob(os.path.join(captcha_images_directory, \"*.png\"))\n",
    "    attributes = list(map(get_captcha_label, files))\n",
    "\n",
    "    data_frame = pandas.DataFrame(attributes)\n",
    "    data_frame['file'] = files\n",
    "    data_frame.columns = ['label', 'file']\n",
    "    data_frame = data_frame.dropna()\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a6da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_split_data(data_frame):\n",
    "    \"\"\"\n",
    "        Shuffle and split the data into 3 sets: training, validation, and testing.\n",
    "    \n",
    "    Args:\n",
    "        data_frame (pandas.DataFrame): the data to shuffle and split\n",
    "    \n",
    "    Returns:\n",
    "        3 numpy.ndarray objects -> (train_indices, validation_indices, test_indices)\n",
    "        each hold the index positions for data in the pandas.DataFrame \n",
    "    \"\"\"\n",
    "    shuffled_indices = numpy.random.permutation(len(data_frame))\n",
    "    train_up_to = int(len(data_frame) * 0.7)\n",
    "    train_indices = shuffled_indices[:train_up_to]\n",
    "    test_indices = shuffled_indices[train_up_to:]\n",
    "\n",
    "    # Further split up the training data.\n",
    "    train_up_to = int(train_up_to * 0.7)\n",
    "    train_indices, validation_indices = train_indices[:train_up_to], train_indices[train_up_to:]\n",
    "    \n",
    "    return train_indices, validation_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccfe46",
   "metadata": {},
   "source": [
    "---\n",
    "**'relu'** stands for **'Rectified Linear Unit'**, the most commonly used activation function for convolutional neural networks.\n",
    "\n",
    "**'softmax'** is another activation function used for classifying data.\n",
    "\n",
    "Activation functions are analagous to the 'firing' of neurons in biological neural networks.\n",
    "\n",
    "**Layers**:\n",
    "- Convolutional layer: applies a filter to the CAPTCHA image to extract features (characters and/or digits) from the image\n",
    "- Pooling layer: immediately follows a convolutional layer and used to downscale the image after each filter is applied\n",
    "- Flattening layer: converts the CAPTCHA image represented as a 3D tensor (array) to a 1D tensor\n",
    "- Dense layer: used to assist with operations on an n-dimensional tensor such as rotation, scaling, etc\n",
    "- Reshape layer: used to restructure the output of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694929f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_untrained_model(image_height=100, image_width=100, image_channels=3, \n",
    "                           character_length=4, categories=10):\n",
    "\n",
    "    input_layer = tensorflow.keras.Input(shape=(image_height, image_width, image_channels))\n",
    "\n",
    "    hidden_layers = layers.Conv2D(32, 3, activation='relu')(input_layer)\n",
    "    hidden_layers = layers.MaxPooling2D((2, 2))(hidden_layers)\n",
    "    hidden_layers = layers.Conv2D(64, 3, activation='relu')(hidden_layers)\n",
    "    hidden_layers = layers.MaxPooling2D((2, 2))(hidden_layers)\n",
    "    hidden_layers = layers.Conv2D(64, 3, activation='relu')(hidden_layers)\n",
    "    hidden_layers = layers.MaxPooling2D((2, 2))(hidden_layers)\n",
    "\n",
    "    hidden_layers = layers.Flatten()(hidden_layers)\n",
    "\n",
    "    hidden_layers = layers.Dense(1024, activation='relu')(hidden_layers)\n",
    "    hidden_layers = layers.Dense(character_length * categories, activation='softmax')(hidden_layers)\n",
    "    hidden_layers = layers.Reshape((character_length, categories))(hidden_layers)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=hidden_layers)\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4ef21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_untrained_alternative_model(image_height=100, image_width=100, image_channels=3, \n",
    "                                       character_length=4, categories=10):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(image_height, image_width, image_channels)))\n",
    "    \n",
    "    model.add(Conv2D(filters=16, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1024,activation='relu'))\n",
    "    model.add(Dense(character_length * categories, activation='softmax'))\n",
    "    model.add(Reshape((character_length, categories)))\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9f5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_untrained_vgg16_model(image_height=100, image_width=100, image_channels=3, \n",
    "                                 character_length=4, categories=10):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(shape=(image_height, image_width, image_channels)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=4096,activation='relu'))\n",
    "    model.add(Dense(units=4096,activation='relu'))\n",
    "    model.add(Dense(character_length * categories, activation='softmax'))\n",
    "    \n",
    "    model.add(Reshape((character_length, categories)))\n",
    "    \n",
    "    opt = SGD(learning_rate=0.01)\n",
    "\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics= ['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b98182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_captcha_generator(data_frame, indices, for_training, batch_size=16, image_height=100, image_width=100,\n",
    "                          categories=10):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        data_frame (pandas.DataFrame): contains the file paths to the CAPTCHA images and their labels\n",
    "        \n",
    "        indices (int): specifies training indices, testing indices, or validation indices of the DataFrame\n",
    "        \n",
    "        for_training (bool): 'True' for training or validation set, 'False' to specify a test set \n",
    "        \n",
    "        batch_size (int): number of data instances to return when iterated upon\n",
    "        \n",
    "        image_height (int): height in pixels to resize the CAPTCHA image to\n",
    "        \n",
    "        image_width (int): width in pixels to resize the CAPTCHA image to\n",
    "        \n",
    "        categories (int): number of possible values for each position in the CAPTCHA image\n",
    "    \n",
    "    Returns:\n",
    "        a generator object for producing CAPTCHA images along with their labels\n",
    "        \n",
    "    Yields:\n",
    "        a pair of lists -> (CAPTCHA images, labels)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    \n",
    "    while True:\n",
    "        for i in indices:\n",
    "            captcha = data_frame.iloc[i]\n",
    "            file, label = captcha['file'], captcha['label']\n",
    "            captcha_image = Image.open(file)\n",
    "            captcha_image = captcha_image.resize((image_height, image_width))\n",
    "            captcha_image = numpy.array(captcha_image) / 255.0\n",
    "            images.append(numpy.array(captcha_image))\n",
    "            labels.append(numpy.array([numpy.array(to_categorical(int(i), categories)) for i in label]))\n",
    "            if len(images) >= batch_size:\n",
    "                yield numpy.array(images), numpy.array(labels)\n",
    "                images, labels = [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad7abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add parameters to satisfy what is required for 'get_captcha_generator' function\n",
    "def train_model(model, data_frame, train_indices, validation_indices, \n",
    "                training_batch_size, validation_batch_size, training_epochs):\n",
    "    \n",
    "    training_set_generator = get_captcha_generator(data_frame, \n",
    "                                                   train_indices,\n",
    "                                                   for_training=True, \n",
    "                                                   batch_size=training_batch_size)\n",
    "    \n",
    "    validation_set_generator = get_captcha_generator(data_frame, \n",
    "                                                     validation_indices,\n",
    "                                                     for_training=True, \n",
    "                                                     batch_size=validation_batch_size)\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "    ]\n",
    "\n",
    "    history = model.fit(training_set_generator,\n",
    "                        steps_per_epoch=len(train_indices)//training_batch_size,\n",
    "                        epochs=training_epochs,\n",
    "                        validation_data=validation_set_generator,\n",
    "                        validation_steps=len(validation_indices)//validation_batch_size)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5df7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    figure, axes = pyplot.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].plot(history.history['accuracy'], label='Training accuracy')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].legend() \n",
    "\n",
    "    axes[1].plot(history.history['loss'], label='Training loss')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation loss')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49fd2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add parameters to satisfy what is required for 'get_captcha_generator' function\n",
    "def get_prediction_results(model, data_frame, test_indices, testing_batch_size):\n",
    "    testing_set_generator = get_captcha_generator(data_frame, \n",
    "                                                  test_indices, \n",
    "                                                  for_training=False, \n",
    "                                                  batch_size=testing_batch_size)\n",
    "\n",
    "    captcha_images, captcha_text = next(testing_set_generator)\n",
    "\n",
    "    predictions = model.predict_on_batch(captcha_images)\n",
    "\n",
    "    true_values = tensorflow.math.argmax(captcha_text, axis=-1)\n",
    "    predictions = tensorflow.math.argmax(predictions, axis=-1)\n",
    "    \n",
    "    return captcha_images, predictions, true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2be93dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions_from_model(captcha_images, predictions, true_values, total_to_display=30, columns=5):\n",
    "    \"\"\"\n",
    "        Display a plot showing the results of the model's predictions.\n",
    "        Each subplot will contain the CAPTCHA image, the model's prediction value, and the true value (label).\n",
    "        \n",
    "    Args:\n",
    "        captcha_images (PNG image): the CAPTCHA image file\n",
    "        \n",
    "        predictions (EagerTensor): the prediction value made by the model\n",
    "        \n",
    "        true_values (EagerTensor): the label associated with the CAPTCHA image\n",
    "        \n",
    "        total_to_display (int): total number of subplots\n",
    "        \n",
    "        columns (int): number of columns in the plot\n",
    "    \"\"\"\n",
    "    random_indices = numpy.random.permutation(total_to_display)\n",
    "    rows = math.ceil(total_to_display / columns)\n",
    "\n",
    "    figure, axes = pyplot.subplots(rows, columns, figsize=(15, 20))\n",
    "    \n",
    "    for i, image_index in enumerate(random_indices):\n",
    "        result = axes.flat[i]\n",
    "        result.imshow(captcha_images[image_index])\n",
    "        result.set_title('prediction: {}'.format(\n",
    "                         ''.join(map(str, predictions[image_index].numpy()))))\n",
    "        result.set_xlabel('true value: {}'.format(\n",
    "                          ''.join(map(str, true_values[image_index].numpy()))))\n",
    "        result.set_xticks([])\n",
    "        result.set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
